---
title: "Mitigate Crawlers on Prod"
description: "Learn how to mitigate excessive crawler traffic on production servers. This guide covers identifying problematic IPs, warning users, blacklisting IPs using fail2ban and iptables, and suggests implementing NGINX traffic rate limiting for better performance."
---

import { Callout } from "fumadocs-ui/components/callout";
import { Card, Cards } from "fumadocs-ui/components/card";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { Tabs, Tab } from "fumadocs-ui/components/tabs";

# How to Mitigate Crawlers with Excessive Traffic

<Callout type="warn">
  Some programs may hammer Open Food Facts servers, causing serious latency and
  504 errors for all users. This guide helps identify and mitigate such issues.
</Callout>

## Background

<Card title="Common Scenario" description="Understanding the typical crawler problem">

Most excessive crawler traffic comes from users who are unaware that bulk data should be downloaded from [https://world.openfoodfacts.org/data](https://world.openfoodfacts.org/data) instead of web scraping.

</Card>

## Mitigation Process

<Steps>
  <Step title="Identify Problematic IPs">
    Use access logs to find IPs making excessive requests
  </Step>

  <Step title="Analyze Traffic Patterns">
    Examine specific IP activity to understand the behavior
  </Step>

  <Step title="Attempt Contact">Try to reach out to users when possible</Step>

  <Step title="Implement Blocking">
    Use appropriate blocking mechanisms based on server configuration
  </Step>
</Steps>

## Finding Disturbing IPs

### Access Log Analysis

Navigate to your site's access log directory and use the traffic analysis script:

```bash title="Find Top Request IPs"
tail -n 100000 access_log | ./concatenate_by_ip.pl | tail -n 10
```

This command shows IP addresses ranked by number of requests.

### Individual IP Investigation

```bash title="Analyze Specific IP Activity"
tail -n 100000 access_log | grep <ip_address>
```

Use this to examine the activity pattern of a specific IP address.

<Callout type="info">
  Search and facets requests are typically the most resource-consuming
  operations. Product read requests are usually just file reads.
</Callout>

## Contact Attempts

If the User-Agent string provides contact information or identifies the organization:

<Steps>
  <Step title="Identify Contact">
    Look for email addresses, organization names, or project identifiers in
    User-Agent strings
  </Step>

  <Step title="Educational Approach">
    Inform them about the proper data download endpoints at `/data`
  </Step>

  <Step title="Provide Alternatives">
    Direct them to appropriate API documentation and bulk data sources
  </Step>
</Steps>

## Blocking Methods

<Tabs items={["OFF2 Reverse Proxy", "OFF1 Direct", "Future Improvements"]}>
  <Tab value="OFF2 Reverse Proxy">
    ### Using Fail2ban on OFF2
    
    For the reverse proxy server, use the fail2ban nginx-botsearch jail:
    
    ```bash title="Ban IP on OFF2"
    fail2ban-client set nginx-botsearch banip <IP>
    ```
    
    <Callout type="info">
    See the [How to use fail2ban to ban bots](/docs/Infra/how/how-to-fail2ban-ban-bots) guide for more details.
    </Callout>
  </Tab>
  
  <Tab value="OFF1 Direct">
    ### Using iptables on OFF1
    
    For direct blocking on OFF1, use iptables rules:
    
    ```bash title="Block IP with iptables"
    iptables -A INPUT -s <ip_address> -j DROP
    ```
    
    <Callout type="warn">
    This method immediately drops all traffic from the specified IP address.
    </Callout>
  </Tab>
  
  <Tab value="Future Improvements">
    ### Rate Limiting Implementation
    
    Instead of outright blocking, implementing NGINX traffic rate limitation would provide:
    
    - **Graceful degradation** instead of complete blocking
    - **Fair usage** enforcement for all users
    - **Automatic throttling** without manual intervention
    - **Better user experience** for legitimate heavy users
  </Tab>
</Tabs>

## Traffic Analysis Tips

<Cards>
  <Card
    title="High-Impact Requests"
    description="Search and facet operations consume most resources"
  />
  <Card
    title="Low-Impact Requests"
    description="Product page views are typically just file reads"
  />
  <Card
    title="Pattern Recognition"
    description="Look for repeated patterns in request URLs"
  />
  <Card
    title="User-Agent Analysis"
    description="Check for bot identification or contact information"
  />
</Cards>

## Prevention Strategies

### Proactive Measures

<Steps>
  <Step title="Rate Limiting">
    Implement NGINX rate limiting to automatically throttle excessive requests
  </Step>

  <Step title="Documentation">
    Improve visibility of bulk data download options
  </Step>

  <Step title="API Guidelines">
    Provide clear API usage guidelines and rate limits
  </Step>

  <Step title="Monitoring">Set up alerts for unusual traffic patterns</Step>
</Steps>

## Related Documentation

<Cards>
  <Card
    title="Fail2ban Bot Blocking"
    description="Detailed guide on using fail2ban to manage bot traffic"
    href="/docs/Infra/how/how-to-fail2ban-ban-bots"
  />
  <Card
    title="Data Downloads"
    description="Official bulk data download location"
    href="https://world.openfoodfacts.org/data"
  />
</Cards>
