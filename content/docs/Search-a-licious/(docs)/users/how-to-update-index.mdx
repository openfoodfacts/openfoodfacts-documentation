---
title: "How to Update Index"
description: "Learn the two strategies for keeping your Search-a-licious index up-to-date. This guide covers both continuous updates via Redis streams and periodic full data re-imports, including initial setup and advanced customization options."
---

import { Callout } from "fumadocs-ui/components/callout";
import { Card, Cards } from "fumadocs-ui/components/card";
import { Steps, Step } from "fumadocs-ui/components/steps";

<Callout type="info">
  As you use search-a-licious, you will first import the data, but then you
  might need to update the index to keep it up to date with the latest data.
</Callout>

## Update Strategies

<Cards>
  <Card
    title="Continuous Updates"
    description="Push events to Redis stream for real-time index updates"
  />
  <Card
    title="Periodic Re-imports"
    description="Update the index periodically using full dataset imports"
  />
</Cards>

<Steps>
<Step title="First Import">

First import will populate Elasticsearch index with all the data.

<Cards>
  <Card
    title="Tutorial Guide"
    href="./tutorial#initial-import"
    description="See initial import section in tutorial"
  />
  <Card
    title="CLI Reference"
    href="../devs/ref-python/cli.html#python3-m-app-import"
    description="Import reference documentation"
  />
</Cards>

<Callout type="warning">
**Important Note**

If you don't use the _continuous updates_ strategy, you need to use the `--skip-updates` option.

</Callout>

</Step>
<Step title="Continuous Updates">

<Callout>
  To have continuous updates, you need to push events to the Redis stream.
  Normally this will be done by your application.
</Callout>

### Event Requirements

On each update/removal/etc. your application must push events with at least:

- The document id
- Eventually more info (if you need them to filter out items, for example)

<Callout type="info">
  You can also push events from another service if you have another way of
  getting changes, but this part is up to you.
</Callout>

### Run the Updater

Start the `updater` container that comes in the docker-compose configuration:

```bash title="Start Continuous Updater"
docker-compose up -d updater
```

This will continuously fetch updates from the event stream and update the index accordingly.

<Card
  title="Configuration Reference"
  href="./ref-config/searchalicious-config-schema.html#indices_additionalProperties_index_last_modified_field_name"
>
  At start it will compute last update time using the `last_modified_field_name`
  from the configuration
</Card>

</Step>
<Step title="Periodic Re-imports">

<Callout>
  Another way to update the index is to periodically re-import all the data, or
  changed data.
</Callout>

This is less compelling to your users, but this might be the best way if you are using an external database publishing changes on a regular basis.

<Card
  title="Import Command"
  href="../devs/ref-python/cli.html#python3-m-app-import"
>
  For that you can use the `import` command
</Card>

**Key Options:**

- Use `--skip-updates` option
- Use `--partial` option if importing only changed data
- For full reimports, use the normal import process (creates a new index that can be rolled back)

</Step>
</Steps>

## Advanced Configuration

<Callout type="info">
**Document Processing**

In the configuration, you can define advanced processing options to transform the data.

</Callout>

<Cards>
  <Card
    title="Document Fetcher"
    href="./ref-config/searchalicious-config-schema.html#indices_additionalProperties_document_fetcher"
    description="Used only on continuous updates"
  />
  <Card
    title="Preprocessor"
    href="./ref-config/searchalicious-config-schema.html#indices_additionalProperties_preprocessor"
    description="Used on both continuous updates and initial import"
  />
</Cards>

<Callout type="info">
  Those are fully qualified dotted names to Python classes.
</Callout>
